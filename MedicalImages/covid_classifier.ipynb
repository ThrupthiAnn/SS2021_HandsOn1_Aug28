{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThrupthiAnn/SS2021_HandsOn1_Aug28/blob/main/MedicalImages/covid_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdnDOtCa5KEQ"
      },
      "source": [
        "# COVID detection from Chest X-Ray\n",
        "---\n",
        "In this module, normal vs COVID classification is performed using Chest X-ray images.\n",
        "The COVIDx dataset is used for this task. For details see [COVIDNet open source initiative](https://github.com/lindawangg/COVID-Net)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j1yXasiZT3E"
      },
      "source": [
        "# Connect drive (optional)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSNgIc9ase0i"
      },
      "source": [
        "# Download data\n",
        "! wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ov4AnT6lIEC9GDsAxO855QKERZydNBJg' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1ov4AnT6lIEC9GDsAxO855QKERZydNBJg\" -O covidx.tar.gz && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqUD4FC7jvDL"
      },
      "source": [
        "! tar -xzf /content/covidx.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLmY7UZwZppq"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BPbdFGEPd6z"
      },
      "source": [
        "! pip install kornia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_syGMRhgov9x"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from tqdm import trange\n",
        "from kornia.utils import one_hot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5npcVLQEl-aJ"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0lSQbSAlFlk"
      },
      "source": [
        "class ImageLoader(Dataset):\n",
        "  \"\"\" Data loader class \"\"\"\n",
        "  def __init__(self, path, file_list, aug_list=None, aug_prob=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      path (str): path where images stored\n",
        "      file_list (List[str]): list of images in current split\n",
        "      aug_list (List[str]): list of torchvision transforms\n",
        "      aug_prob (float): Probability of applying random aug (if aug_list != None)\n",
        "    \"\"\"\n",
        "    self.path = path\n",
        "    self.file_list = file_list\n",
        "    self.aug_list = aug_list\n",
        "    self.aug_prob = aug_prob\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_list)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\" Preprocess and return a single sample & label \"\"\"\n",
        "    img_name = os.path.join(self.path, self.file_list[idx])\n",
        "    img = Image.open(img_name)\n",
        "    # Resize to 256, 256 with LANCZOS interpolation\n",
        "    img = img.resize((256, 256), Image.LANCZOS)\n",
        "    img = np.array(img)\n",
        "    if len(img.shape) < 3:\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    if img.shape[2] == 4:\n",
        "      img = img[:, :, :3]\n",
        "    # file names are in format covidx_(label)_(name)\n",
        "    label = int(img_name.split('_')[1])\n",
        "    if label == 2:\n",
        "      label -= 1  # as COVID is 2 in file names\n",
        "    label = torch.Tensor([label])\n",
        "\n",
        "    # convert to Tensor and change order to channels first  \n",
        "    img = torch.Tensor(img)\n",
        "    img = img.permute(2, 0, 1)\n",
        "\n",
        "    # select and apply random augmentation (if passed)\n",
        "    if self.aug_list:\n",
        "      do_aug = np.random.choice([True, False], 1, p=[self.aug_prob,\n",
        "                                                     1-self.aug_prob])\n",
        "      if do_aug:\n",
        "        aug_name = np.random.choice(self.aug_list, 1)\n",
        "        img = aug_name[0](img)\n",
        "    img = (img - torch.mean(img)) / torch.std(img)\n",
        "    return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pU9_SjM0pax"
      },
      "source": [
        "def get_data_loaders(categories, path, file_lists,\n",
        "                     augment, aug_prob, batch_size):\n",
        "  \"\"\"\n",
        "  Wrapper function to return dataloader(s)\n",
        "  Args:\n",
        "    categories (List[str]): names of processes for which dataloader needed\n",
        "    path (str): path where images stored\n",
        "    file_lists (List[List[str]]): list of file lists\n",
        "    augment (boolean): whether to apply augmentation\n",
        "    aug_prob (float): Probability of applying random aug\n",
        "    batch_size (int): batch size\n",
        "  Returns:\n",
        "    torch.utils.data.DataLoader object\n",
        "  \"\"\"\n",
        "  loaders = []\n",
        "  for i, category in enumerate(categories):\n",
        "    if category == 'train' and augment:\n",
        "      aug_list = [\n",
        "          transforms.RandomAffine(0, translate=(0.2, 0.2)),\n",
        "          transforms.RandomHorizontalFlip(p=1),\n",
        "          transforms.RandomRotation(degrees=(-10, 10), fill=(0,)),\n",
        "          transforms.GaussianBlur((17, 17), (11, 11))\n",
        "      ]\n",
        "    else:\n",
        "      aug_list = None\n",
        "    loader = DataLoader(\n",
        "        ImageLoader(path, file_lists[i], aug_list, aug_prob),\n",
        "        batch_size,\n",
        "        num_workers=1\n",
        "        )\n",
        "    loaders.append(loader)\n",
        "  return loaders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPhL86aF4sjb"
      },
      "source": [
        "## Train/val/test loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLnI2nmj2XZK"
      },
      "source": [
        "def learn(model, loader, optimizer, loss_fn, process):\n",
        "  \"\"\" main function for single epoch of train, val or test \"\"\"\n",
        "  all_labels = []\n",
        "  all_preds = []\n",
        "  running_loss = 0\n",
        "  num_batches = len(loader)\n",
        "  with trange(num_batches, desc=process, ncols=100) as t:\n",
        "    for batch_num, sample in enumerate(loader):\n",
        "      img_batch, labels = sample\n",
        "      labels = torch.reshape(labels, (-1,))\n",
        "      labels_oh = one_hot(labels.long(), 2, 'cpu', labels.dtype).cuda()\n",
        "      if process == 'train':                \n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        preds = F.softmax(model(img_batch.cuda()), 1)\n",
        "        loss = loss_fn(preds[:, 0], labels_oh[:, 0])\n",
        "        loss += loss_fn(preds[:, 1], labels_oh[:, 1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      else:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "          preds = F.softmax(model(img_batch.cuda()), 1)\n",
        "          # loss = loss_fn(preds, labels.cuda())\n",
        "          loss = loss_fn(preds[:, 0], labels_oh[:, 0])\n",
        "          loss += loss_fn(preds[:, 1], labels_oh[:, 1])\n",
        "      hard_preds = torch.argmax(preds, 1)\n",
        "      all_labels += labels.numpy().tolist()\n",
        "      all_preds += hard_preds.detach().cpu().numpy().tolist()\n",
        "      running_loss += loss  \n",
        "      t.set_postfix(loss=running_loss.item()/(float(batch_num+1)*batch_size))\n",
        "      t.update()\n",
        "  acc = accuracy_score(all_labels, all_preds)\n",
        "  f1 = f1_score(all_labels, all_preds)\n",
        "  final_loss = running_loss.item()/(num_batches*batch_size)\n",
        "  return acc, f1, final_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QjMxW-3C41l"
      },
      "source": [
        "def get_splits(all_names, train_size, val_size, test_size, all_labels):\n",
        "  split1_size = (val_size+test_size)\n",
        "  split2_size = test_size / (val_size+test_size)\n",
        "  trn_names, valtst_names, trn_y, valtst_y = train_test_split(\n",
        "      all_names, all_labels, test_size=split1_size,\n",
        "      stratify=all_labels, random_state=0)\n",
        "  val_names, tst_names = train_test_split(valtst_names, test_size=split2_size,\n",
        "                              stratify=valtst_y, random_state=0)\n",
        "  return trn_names, val_names, tst_names "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SsSa05k__2U"
      },
      "source": [
        "def perform_learning(model, optimizer, loss_fn, path, all_names, batch_size,\n",
        "                     splits, num_epochs):\n",
        "  \"\"\" Wrapper function to run train, val, test loops \"\"\"\n",
        "  all_labels = [int(name.split('_')[1]) for name in all_names]\n",
        "  train_size, val_size, test_size = splits\n",
        "  trn_names, val_names, tst_names = get_splits(all_names, train_size, val_size,\n",
        "                                               test_size, all_labels)\n",
        "  train_loader, val_loader, test_loader = get_data_loaders(\n",
        "      ['train', 'val', 'test'],\n",
        "      path, [trn_names, val_names, tst_names],\n",
        "      augment=True,\n",
        "      aug_prob=0.5,\n",
        "      batch_size=batch_size\n",
        "      )\n",
        "  for epoch_num in range(num_epochs):\n",
        "    trn_acc, trn_f1, trn_loss = learn(model, train_loader, optimizer, loss_fn,\n",
        "                                      'train')\n",
        "    print(f'Training Epoch {epoch_num} - Loss: {trn_loss} ; Accuracy: {trn_acc}'\n",
        "          f' ; F1 Score: {trn_f1}')\n",
        "    val_acc, val_f1, val_loss = learn(model, val_loader, optimizer, loss_fn,\n",
        "                                      'val')\n",
        "    print(f'Validation Epoch {epoch_num} - Loss: {val_loss} ; Accuracy: {val_acc}'\n",
        "          f' ; F1 Score: {val_f1}')\n",
        "  tst_acc, tst_f1, tst_loss = learn(model, test_loader, optimizer, loss_fn,\n",
        "                                    'test')\n",
        "  print(f'Test - Loss: {tst_loss} ; Accuracy: {tst_acc}'\n",
        "        f' ; F1 Score: {tst_f1}')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4llZPlvHbxa"
      },
      "source": [
        "## Let's run!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WMbMigmHVhn"
      },
      "source": [
        "path = '/content/covidx'\n",
        "all_names = os.listdir(path)[:500]\n",
        "\n",
        "lr = 1e-4\n",
        "wt_dec = 1e-4\n",
        "num_epochs = 5\n",
        "batch_size = 32\n",
        "splits = [0.8, 0.1, 0.1]\n",
        "\n",
        "model = resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, 2)\n",
        "model = model.cuda()\n",
        "\n",
        "# loss_fn = nn.BCEWithLogitsLoss(reduction='sum')\n",
        "loss_fn = nn.BCELoss(reduction='sum')\n",
        "optimizer = Adam(model.parameters(), lr=lr, weight_decay=wt_dec)\n",
        "\n",
        "perform_learning(model, optimizer, loss_fn, path, all_names, batch_size,\n",
        "                 splits, num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqP6HROCiKr7"
      },
      "source": [
        "# Save model (optional)\n",
        "# torch.save(model.state_dict(), '/content/gdrive/My Drive/covidx_500subset_softmax.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JXW4DLPFs_N"
      },
      "source": [
        "# **Explanation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PuTDO4Vv4kx"
      },
      "source": [
        "# run this if loading the model later (optional)\n",
        "# model = resnet18(pretrained=True)\n",
        "# model.fc = nn.Linear(512, 2)\n",
        "# model.load_state_dict(torch.load('/content/gdrive/My Drive/covidx_500subset_softmax.pt'))\n",
        "# model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2MJH5efdRi3"
      },
      "source": [
        "! pip install captum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHvoPhto3kp7"
      },
      "source": [
        "# Interpretation\n",
        "import captum.attr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = '/content/covidx'\n",
        "all_names = os.listdir(path)[:500]\n",
        "all_labels = [int(name.split('_')[1]) for name in all_names]\n",
        "splits = [0.8, 0.1, 0.1]\n",
        "train_size, val_size, test_size = splits\n",
        "trn_names, val_names, tst_names = get_splits(all_names, train_size, val_size,\n",
        "                                              test_size, all_labels)\n",
        "_, _, test_loader = get_data_loaders(\n",
        "    ['train', 'val', 'test'],\n",
        "    path, [trn_names, val_names, tst_names],\n",
        "    augment=True,\n",
        "    aug_prob=0.5,\n",
        "    batch_size=1\n",
        "    )\n",
        "\n",
        "cnt = 0\n",
        "for batch_num, sample in enumerate(test_loader):\n",
        "  X, label = sample\n",
        "\n",
        "  gcObj = captum.attr.LayerGradCam(model.forward, model.layer4)     \n",
        "  if label.item() == 0:\n",
        "    continue                            \n",
        "  attr = gcObj.attribute(X.cuda(), int(label.item()))                                                                     \n",
        "  attr = torch.abs(attr)                                                                                  \n",
        "  attrRescaled = Image.fromarray(attr.detach().cpu()                                                      \n",
        "                                 .numpy()[0, 0, :, :]).resize(                                            \n",
        "                                 (X.shape[3], X.shape[2]))\n",
        "  img = X[0].permute(1, 2, 0).numpy()\n",
        "  img = img.astype('float')\n",
        "  img = (img - np.max(img)) / (np.max(img) - np.min(img))\n",
        "  attr_map = np.array(attrRescaled)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow((img*255).astype('uint8'), cmap='gray')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow((img*255).astype('uint8'), cmap='gray')\n",
        "  plt.imshow(attr_map, cmap='jet', alpha=0.3)  \n",
        "  plt.axis('off')\n",
        "#   plt.colorbar()\n",
        "  plt.show()                 \n",
        "  cnt += 1\n",
        "  if cnt >= 10:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lgRdbsdxd5m"
      },
      "source": [
        "# **Excercise**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   Plot the confusion matrix\n",
        "*   Check other metrics\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TBeiV6ox2gJ"
      },
      "source": [
        "# **Resources**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* Try tensorboard  \n",
        "* Check out [Weights and Biases](https://wandb.ai/site)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H4PQ8WHyEJt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}